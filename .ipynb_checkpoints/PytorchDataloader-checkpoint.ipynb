{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " %config Completer.use_jedi = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from modules.utils.render import Renderer\n",
    "from modules.utils.geometry import batch_rodrigues, rotation_matrix_to_angle_axis\n",
    "from modules.utils.image_utils import transform, transform_visualize, crop_box, plot_tensor\n",
    "from modules.smpl_model.smpl import SMPL, SMPL_MODEL_DIR , get_smpl_faces\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import torch\n",
    "from modules.dataset_3DPW import ImageWise3DPW\n",
    "from modules.utils.data_utils import get_relevant_keypoints\n",
    "from modules.utils.image_utils import transform, transform_visualize, crop_box, plot_tensor\n",
    "from modules.utils.image_utils import to_tensor, visualize_mesh\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: 3DPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ImageWise3DPW(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_path:str,\n",
    "        split:str = 'train',\n",
    "        num_required_keypoints:int = 0,\n",
    "        store_sequences=True,\n",
    "        store_images=True,\n",
    "    ):\n",
    "        super(ImageWise3DPW, self).__init__()\n",
    "        self.sequence_path = osp.join(root_path, 'sequenceFiles', split)\n",
    "        self.seq_names = [seq_name.split('.pkl')[0] for seq_name in sorted(os.listdir(self.sequence_path))]\n",
    "        self.split = split\n",
    "        self.num_required_keypoints = num_required_keypoints\n",
    "        self.store_sequences = store_sequences\n",
    "        self.sequences = {}\n",
    "        self.store_images = store_images\n",
    "\n",
    "        person_ids = []\n",
    "        image_paths = []\n",
    "        for seq_name in self.seq_names:\n",
    "            img_dir = osp.join(root_path, 'imageFiles', seq_name)\n",
    "            \n",
    "            seq_file_name = os.path.join(self.sequence_path, f'{seq_name}.pkl')\n",
    "            with open(seq_file_name, 'rb') as f:\n",
    "                seq = pkl.load(f, encoding='latin1')\n",
    "            if store_sequences:\n",
    "                self.sequences[seq_name] = seq\n",
    "                \n",
    "            num_people = len(seq['poses'])\n",
    "            \n",
    "            for img_idx, img_name in enumerate(sorted(os.listdir(img_dir))):\n",
    "                image_path = osp.join(img_dir,img_name)\n",
    "                for person_id in range(num_people):\n",
    "                    pose2d = seq['poses2d'][person_id][img_idx]\n",
    "                    relevant_poses2d = get_relevant_keypoints(pose2d)\n",
    "                    if len(relevant_poses2d) >= self.num_required_keypoints:\n",
    "                        image_paths.append(image_path)\n",
    "                        person_ids.append(person_id)\n",
    "            \n",
    "        self.image_paths = image_paths\n",
    "        self.person_ids = person_ids\n",
    "        \n",
    "        self.to_tensor = lambda arr: torch.from_numpy(arr.astype(np.float32)).permute(2,0,1)/255.\n",
    "        \n",
    "        if self.store_images:\n",
    "            self.img_cache_indicator = torch.zeros(self.__len__(), dtype=torch.bool)\n",
    "            self.img_cache = torch.empty(self.__len__(), 3, 224, 224, dtype=torch.float32)\n",
    "        \n",
    "        self.timers = {\n",
    "            'load_image': 0,\n",
    "            'load_sequence': 0,\n",
    "            #'image_to_tensor': 0,\n",
    "            #'crop_box': 0,\n",
    "            'transform_image': 0,\n",
    "            'out': 0,\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        t_start = time.time()\n",
    "        \n",
    "        # load image\n",
    "        # img = np.array(Image.open(img_path))\n",
    "        t_load_image = time.time()\n",
    "\n",
    "        # load sequence\n",
    "        img_path = self.image_paths[index]\n",
    "        _, img_name = os.path.split(img_path)\n",
    "        seq_name = img_path.split('/')[-2]\n",
    "        \n",
    "        if self.store_sequences:\n",
    "            seq = self.sequences[seq_name]\n",
    "        else:\n",
    "            seq_file_name = os.path.join(self.sequence_path, f'{seq_name}.pkl')\n",
    "            with open(seq_file_name, 'rb') as f:\n",
    "                seq = pkl.load(f, encoding='latin1')\n",
    "            \n",
    "        index_seq = int((img_name.split('.')[0]).split('_')[1])\n",
    "        person_id = self.person_ids[index]\n",
    "        \n",
    "        poses2d = torch.tensor(seq['poses2d'][person_id][index_seq], dtype=torch.float32)\n",
    "        \n",
    "        poses3d = torch.tensor(seq['jointPositions'][person_id][index_seq], dtype=torch.float32) \n",
    "        poses3d = poses3d.view(-1, 24,3)\n",
    "        \n",
    "        t_load_sequence = time.time()\n",
    "    \n",
    "        # Resize Image to 224x224 format with padding\n",
    "        if self.store_images and self.img_cache_indicator[index]:\n",
    "            img_tensor = self.img_cache[index]\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path))\n",
    "\n",
    "            img_tensor1 = self.to_tensor(img)\n",
    "            img_tensor2 = transforms.ToTensor()(img)\n",
    "\n",
    "            #img_tensor = transforms.ToTensor()(img)\n",
    "        \n",
    "            img_tensor1, _ = crop_box(img_tensor=img_tensor1, pose2d=poses2d)\n",
    "            img_tensor2, _ = crop_box(img_tensor=img_tensor2, pose2d=poses2d)\n",
    "\n",
    "            #img_tensor1 = transform(img_tensor1)\n",
    "            #img_tensor2 = transform(img_tensor2)\n",
    "\n",
    "            img_tensor = transform(img_tensor1)\n",
    "            if self.store_images:\n",
    "                self.img_cache[index] = img_tensor\n",
    "                self.img_cache_indicator[index] = True\n",
    "                \n",
    "        t_preprocess_image = time.time()\n",
    "        \n",
    "        data = {}\n",
    "        data['img_path'] = img_path\n",
    "        data['img1'] = img_tensor1\n",
    "        data['img2'] = img_tensor2\n",
    "        data['betas'] = torch.tensor(seq['betas'][person_id][:10], dtype=torch.float32)\n",
    "        data['cam_pose'] = torch.tensor(seq['cam_poses'][index_seq], dtype=torch.float32)    \n",
    "        data['poses'] = torch.tensor(seq['poses'][person_id][index_seq], dtype=torch.float32) \n",
    "        data['poses2d'] = poses2d \n",
    "        data['poses3d'] = poses3d\n",
    "        data['cam_pose'] = torch.tensor(seq['cam_poses'][index_seq], dtype=torch.float32)  \n",
    "        data['cam_intr'] = torch.tensor(seq['cam_intrinsics'], dtype=torch.float32)\n",
    "        data['trans'] = torch.tensor(seq['trans'][person_id][index_seq], dtype=torch.float32)\n",
    "        \n",
    "        t_out = time.time()\n",
    "        \n",
    "        self.timers['load_image'] += t_load_image - t_start\n",
    "        self.timers['load_sequence'] += t_load_sequence - t_load_image\n",
    "        #self.timers['image_to_tensor'] += t_image_to_tensor - t_load_sequence\n",
    "        #self.timers['crop_box'] += t_crop_box - t_image_to_tensor\n",
    "        self.timers['transform_image'] += t_preprocess_image - t_load_sequence\n",
    "        \n",
    "        self.timers['out'] += t_out - t_preprocess_image\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageWise3DPW(\n",
    "    root_path=cfg.dataset_to_path['3dpw'],\n",
    "    num_required_keypoints=8,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=1,\n",
    "        shuffle=False,)\n",
    "train_iter = iter(train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(train_iter)\n",
    "img = data['img']\n",
    "betas = data['betas']\n",
    "poses = data['poses']\n",
    "poses2d = data['poses2d']\n",
    "cam_pose = data['cam_pose']\n",
    "cam_intr = data['cam_intr']\n",
    "trans = data['trans']\n",
    "poses3d = data['poses3d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224]) torch.Size([1, 10]) torch.Size([1, 72]) torch.Size([1, 3, 18]) torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(img.shape, betas.shape, poses.shape, poses2d.shape, cam_pose.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = ImageWise3DPW(root_path=cfg.dataset_to_path['3dpw'], split = 'validation')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=10, \n",
    "        shuffle=False,)\n",
    "\n",
    "val_iter = iter(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tensor(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_next = next(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ConcatDatasets(torch.utils.data.Dataset)\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "        sum_length = 0\n",
    "        self.accumulated_lens = [0]\n",
    "        for dataset in datasets:\n",
    "            sum_length += len(dataset)\n",
    "            self.accumulated_lens.append(sum_length)\n",
    "    \n",
    "    def __get_item__(self, index):\n",
    "        for i, accumulated_len in enumerate(self.accumulated_lens):\n",
    "            if accumulated_len > index:\n",
    "                return self.datasets[i][index-self.accumulated_lens[i-1]+1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return accumulated_lens[-1]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import get_model\n",
    "from start_train import start_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoseNetXtreme(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=1000, out_features=128, bias=True)\n",
       "  (decoder): PoseDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (linear_beta): Linear(in_features=128, out_features=10, bias=True)\n",
       "    (linear_pose): Linear(in_features=128, out_features=72, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6890, 3]) torch.Size([16, 6890, 3])\n",
      "torch.Size([16, 6890, 3]) torch.Size([16, 6890, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-538ac1217e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/MeineProjekte/HMR_3DWP/start_train.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(model_param, num_epochs, criterion, metrics, batch_size_trn, batch_size_val, learning_rate)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbatch_size_trn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size_trn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbatch_size_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     )\n",
      "\u001b[0;32m~/Desktop/MeineProjekte/HMR_3DWP/modules/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, data_trn, data_val, criterion, metrics, batch_size_trn, batch_size_val, learning_rate, device)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mloss_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_trn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}; Loss Trn: {loss_trn}; Loss Val: {loss_val}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MeineProjekte/HMR_3DWP/modules/training.py\u001b[0m in \u001b[0;36mtrn_loop\u001b[0;34m(model, optimizer, loader_trn, criterion, metrics, device)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MeineProjekte/HMR_3DWP/modules/training.py\u001b[0m in \u001b[0;36m_loop\u001b[0;34m(train, model, optimizer, loader, criterion, metrics, device)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mloss_mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/hmr-ba/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/hmr-ba/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = SMPL(SMPL_MODEL_DIR)\n",
    "body_pose = poses[:1,3:]\n",
    "global_orient = poses[:1,:3]\n",
    "\n",
    "out = smpl(betas[:1,:10], body_pose, global_orient) ## SMPLX w/out translation\n",
    "gt_vertices = out.vertices\n",
    "\n",
    "out1 = smpl(betas[:1,:10], body_pose, global_orient, trans[:1,]) ## SMPLX with translation\n",
    "gt_vertices1 = out1.vertices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Losses \n",
    "## SMPL\n",
    "## Vertices --> Normalize Vertices with SMPL Pelvis \n",
    "## Joints2D\n",
    "## Joints3D Convert to 14x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 1080\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-63bd6c38276f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0morig_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrend_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_intr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrend_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MeineProjekte/HMR_3DWP/modules/utils/image_utils.py\u001b[0m in \u001b[0;36mvisualize_mesh\u001b[0;34m(img, beta, pose, cam_pose, cam_intr, trans)\u001b[0m\n\u001b[1;32m    127\u001b[0m                                \u001b[0muse_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                                \u001b[0mfocal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfocal_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                                body_color = color)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m#return torch.Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MeineProjekte/HMR_3DWP/modules/utils/render.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, vertices, faces, img, cam_t, cam_rot, cam_center, cam_f, use_bg, bg_color, body_color, focal_length, disp_text, gt_keyp, pred_keyp, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                              \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_center\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                              k = np.zeros(5))\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mfar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "img_path = data['img_path'][0]\n",
    "orig_img = to_tensor(Image.open(img_path))\n",
    "\n",
    "rend_img = visualize_mesh(orig_img, betas, poses, cam_pose, cam_intr[0], trans)\n",
    "plot_tensor(rend_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from modules.utils.geometry import rotation_matrix_to_angle_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# INPUT: betas: torch.Tensor([1, Pcs]), poses: torch.Tensor([1,72]), trans: torch.Tensor([1,3])\n",
    "# cam_pose: torch.Tensor([4,4]), cam_intr: torch.Tensor([3, 3])\n",
    "def visualize_mesh(img, beta, pose, cam_pose, cam_intr, trans = None):\n",
    "    cam_pose = cam_pose.detach().numpy()\n",
    "    cam_intr = cam_intr.detach().numpy()\n",
    "\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy().transpose(1,2,0)\n",
    "   \n",
    "\n",
    " ## get smpl faces and vertices ##\n",
    "\n",
    "    #SMPLX Model: \n",
    "    smpl = SMPL(SMPL_MODEL_DIR)\n",
    "    body_pose = pose[:,3:]\n",
    "    global_orient = pose[:,:3]\n",
    "    out = smpl(beta, body_pose, global_orient, trans) ## SMPLX with translation\n",
    "    vertices = out.vertices\n",
    "    vertices = vertices[0].detach().numpy()\n",
    "    faces = get_smpl_faces()\n",
    "    \n",
    "    # _SMPL from METRO:\n",
    "    #smpl = SMPL()\n",
    "    #vertices = smpl(pose = pose, beta = beta[:10]) + trans\n",
    "    #faces = smpl.faces.cpu().numpy()\n",
    "    \n",
    "\n",
    "    # camera: rotation matrix, t, f and center\n",
    "    cam_rot = cv2.Rodrigues(cam_pose[0:3,0:3])[0].ravel() # --> Rot Matrix to Angle Axis\n",
    "    cam_t = cam_pose[0:3,3]\n",
    "    cam_f = np.array([cam_intr[0,0],cam_intr[1,1]])\n",
    "    cam_center = cam_intr[0:2,2]\n",
    "\n",
    "\n",
    "\n",
    "    # Visualize Mesh \n",
    "    renderer = Renderer(faces=faces)\n",
    "    color= 'pink'\n",
    "    focal_length = 1000\n",
    "    rend_img = renderer.render(vertices,\n",
    "                               cam_t= cam_t,\n",
    "                               cam_rot= cam_rot,\n",
    "                               cam_center= cam_center,\n",
    "                               cam_f = cam_f,\n",
    "                               img= img, \n",
    "                               use_bg = True,\n",
    "                               focal_length = focal_length,\n",
    "                               body_color = color)\n",
    "\n",
    "    #return torch.Tensor\n",
    "    rend_img = rend_img.transpose(2,0,1)\n",
    "    rend_img = torch.from_numpy(rend_img)\n",
    "    return rend_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0f58b900dc75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcam_pose1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_pose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRodrigues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_pose1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "cam_pose1 = cam_pose.detach().numpy()\n",
    "cv2.Rodrigues(cam_pose1[0][0:3,0:3])[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9583,  0.0367, -0.2833, -0.4611],\n",
       "         [ 0.0878, -0.9816,  0.1697, -1.3847],\n",
       "         [-0.2718, -0.1875, -0.9439,  5.0436]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_pose[0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.9288156 , -0.09384797,  0.4185991 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_matrix_to_angle_axis(cam_pose[0:3,0:3]).detach().numpy().ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9583,  0.0367, -0.2833, -0.4611],\n",
       "         [ 0.0878, -0.9816,  0.1697, -1.3847],\n",
       "         [-0.2718, -0.1875, -0.9439,  5.0436]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_pose[0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_pose1[None, :3,:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a322d6164d4c4b25220498a101ca0aa919a3d35aa42e46c74a12730060a98a1"
  },
  "kernelspec": {
   "display_name": "hmr-ba",
   "language": "python",
   "name": "hmr-ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
