{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.smpl_model._smpl import SMPL as SMPL_metro, H36M_J17_NAME, H36M_J17_TO_J14\n",
    "from modules.utils.image_utils import plot_tensor, to_tensor, visualize_mesh\n",
    "from modules.smpl_model.config_smpl import *\n",
    "from modules.smpl_model.smpl_pose2mesh import SMPL\n",
    "from modules.datasets.dataset_3DPW import get_data as get_data_3dpw\n",
    "from modules.datasets.dataset_H36M import get_data as get_data_h36m\n",
    "from modules.datasets.FullDataset import get_full_train_val_data\n",
    "from modules.utils.data_utils_3dpw import get_chunks_img_paths_list_seq\n",
    "from modules.utils.data_utils_h36m import get_data_list_h36m, get_data_chunk_list_h36m\n",
    "from modules.smpl_model.smpl_pose2mesh import SMPL\n",
    "from modules.utils.geometry import world2cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMPL Model Pose2Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = SMPL()\n",
    "smpl_metro = SMPL_metro()\n",
    "\n",
    "# Adapt Regressor for 10 PCs\n",
    "smpl.layer['neutral'].th_shapedirs= smpl.layer['neutral'].th_shapedirs[:,:,:10]\n",
    "smpl.layer['neutral'].th_betas= smpl.layer['neutral'].th_betas[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 6890)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.joint_regressor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6890, 24])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_metro.weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist1 = get_data_list_h36m('../H36M/annotations', [1], 25, store_as_pkl=False,out_dir='../H36M/data_pickle_kp3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396316/396316 [00:23<00:00, 16594.12it/s]\n"
     ]
    }
   ],
   "source": [
    "datalist5 = get_data_list_h36m('../H36M/annotations', [5], 25, store_as_pkl=False,out_dir='../H36M/data_pickle_kp3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249864/249864 [00:22<00:00, 11119.02it/s]\n"
     ]
    }
   ],
   "source": [
    "datalist6 = get_data_list_h36m('../H36M/annotations', [6], 25, store_as_pkl=False,out_dir='../H36M/data_pickle_kp3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 406484/406484 [00:38<00:00, 10522.99it/s]\n"
     ]
    }
   ],
   "source": [
    "datalist7 = get_data_list_h36m('../H36M/annotations', [7], 25, store_as_pkl=False,out_dir='../H36M/data_pickle_kp3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258712/258712 [00:28<00:00, 8984.27it/s] \n"
     ]
    }
   ],
   "source": [
    "datalist8 = get_data_list_h36m('../H36M/annotations', [8], 25, store_as_pkl=False,out_dir='../H36M/data_pickle_kp3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 317668/317668 [00:45<00:00, 7000.11it/s] \n"
     ]
    }
   ],
   "source": [
    "datalist9 = get_data_list_h36m('../H36M/annotations', [9], 25, store_as_pkl=False,out_dir='../H36M/data_pickle_kp3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231151/231151 [00:06<00:00, 34821.27it/s]\n"
     ]
    }
   ],
   "source": [
    "datalist11 = get_data_list_h36m('../H36M/annotations', [11], 25, store_as_pkl=False,out_dir='../H36M/data_pickle_kp3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_complete = []\n",
    "for datalist in [datalist1, datalist5, datalist6, datalist7, datalist8]:\n",
    "    for data in datalist:\n",
    "        data_list_complete.append(data)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_complete2 = []\n",
    "for datalist in [datalist9, datalist11]:\n",
    "    for data in datalist:\n",
    "        data_list_complete2.append(data)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309300, 74032)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list_complete), len(data_list_complete2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir='../H36M/data_pickle_kp3d'\n",
    "fitting_thr = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_str = f'9to11'\n",
    "with open(osp.join(out_dir, f'datalist_h36m_thr{fitting_thr}_{sub_str}subj.pickle'), 'wb') as fp:\n",
    "     pkl.dump(data_list_complete2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load datalist\n"
     ]
    }
   ],
   "source": [
    "a, b = get_data_chunk_list_h36m(annot_dir=None,\n",
    "                    subject_list=[1,5,6,7,8],\n",
    "                    fitting_thr=25,\n",
    "                    len_chunks=8,\n",
    "                    load_seq_datalist=None,\n",
    "                    load_datalist='/Users/clara/Desktop/MeineProjekte/H36M/data_pickle_kp3d/datalist_h36m_thr25_1to8subj.pickle',\n",
    "                    store_as_pkl=False,\n",
    "                    out_dir='/Users/clara/Desktop/MeineProjekte/H36M/data_pickle_kp3d/',\n",
    "                    seq_datalist=None,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/clara/Desktop/MeineProjekte/H36M/data_pickle_kp3d/'\n",
    "fitting_thr=25\n",
    "sub_str = '1to8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(out_dir, f'seq_datalist_h36m_thr{fitting_thr}_{sub_str}subj.pickle'), 'wb') as fp:\n",
    "    pkl.dump(b, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset H36M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets initialized\n",
      "load datalist\n",
      "datalist h36m, current memory 0.9011497497558594 GB\n",
      "11 ../H36M/img_zarr/imgs_h36m_resnet_thr25_11to11subj.zarr\n",
      "data h36m, current memory 0.901153564453125 GB\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "datah36m = get_data_h36m(data_path='../H36M',\n",
    "                        subject_list = [11],\n",
    "                        img_size=224,\n",
    "                        load_datalist='../H36M/data_pickle_kp3d/datalist_h36m_thr25_11to11subj.pickle', \n",
    "                        load_from_zarr=['../H36M/img_zarr/imgs_h36m_resnet_thr25_11to11subj.zarr'],\n",
    "                        mask=True,\n",
    "                        smpl=smpl.layer['neutral'],\n",
    "                        backgrounds = None,\n",
    "                        store_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_trn = torch.utils.data.DataLoader(\n",
    "        dataset=datah36m,\n",
    "        batch_size=3,\n",
    "        shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = next(iter(loader_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dat['img']\n",
    "img_path= dat['img_path']\n",
    "verts = dat['vertices']\n",
    "cam_pose =dat['cam_pose']\n",
    "cam_intr = dat['cam_intr']\n",
    "trans = dat['trans']\n",
    "joints = np.array(dat['joints_3d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_p2m = smpl.get_joints(verts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joints_p2m[:,:24,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_metro = smpl_metro.get_h36m_joints(verts)\n",
    "joints_metro = joints_metro - joints_metro[:, H36M_J17_NAME.index('Pelvis'),:][:, None, :]\n",
    "joints_metro = np.array(joints_metro[:, H36M_J17_TO_J14, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img = np.array(Image.open(img_path))\n",
    "orig_img = to_tensor(orig_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rend_img = visualize_mesh(orig_img, smpl=smpl_metro, cam_intr=cam_intr, vertices=(verts+trans)[None])\n",
    "plot_tensor(rend_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tensor(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.datasets.FullDataset import get_full_train_val_data\n",
    "from modules.datasets.dataset_3DPW import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3dpw = get_data('../3DPW', \n",
    "'validation', 8, \n",
    "True,\n",
    " False, \n",
    "'/Users/clara/Desktop/MeineProjekte/3DPW/img_zarr/imgs_3dpw_valid.zarr',\n",
    "224,\n",
    "'/Users/clara/Desktop/MeineProjekte/3DPW/data_pickle/ids_imgpaths_seq/ids_paths_seq_validation_min8_kps.pickle',smpl=smpl.layer['neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_trn = torch.utils.data.DataLoader(dataset=data3dpw,\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader_trn))\n",
    "joints = np.array(data['joints_3d'])\n",
    "vertices = data['vertices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_metro = smpl_metro.get_h36m_joints(vertices)\n",
    "joints_metro = joints_metro - joints_metro[:, H36M_J17_NAME.index('Pelvis'),:][:, None, :]\n",
    "joints_metro = np.array(joints_metro[:, H36M_J17_TO_J14, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2062482 , -0.12041646,  3.7628517 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(joints[0],0)[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitting_error(joint3d_h36m_gt, joint3d_smpl):\n",
    "    #joint3d_h36m_gt = joint3d_h36m_gt - joint3d_h36m_gt[H36M_J17_NAME.index('Pelvis'), None,:] # root-relative\n",
    "    # translation alignment\n",
    "    #joint3d_smpl = joint3d_smpl - np.mean(joint3d_smpl,0)[None,:] + np.mean(joint3d_h36m_gt,0)[None,:]\n",
    "    error = np.sqrt(np.sum((joint3d_h36m_gt - joint3d_smpl)**2, 1)).mean()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10538352  0.86494523 -0.1566712 ]\n",
      " [ 0.06657241  0.44574255  0.01868278]\n",
      " [ 0.11751296 -0.0185063   0.09091746]\n",
      " [-0.11842925  0.01930699 -0.08864043]\n",
      " [-0.12712356  0.4465999   0.11958259]\n",
      " [-0.01726985  0.8680906   0.21322313]\n",
      " [ 0.20283544 -0.00961037  0.32306966]\n",
      " [ 0.17730615 -0.2043225   0.16353977]\n",
      " [-0.00404913 -0.42414302  0.14264494]\n",
      " [-0.21976408 -0.37624747 -0.01301892]\n",
      " [-0.21796632 -0.11224277 -0.13877317]\n",
      " [-0.19333783  0.14599812 -0.19696826]\n",
      " [-0.13562497 -0.44751734  0.08347292]\n",
      " [-0.22294733 -0.5827157   0.15034515]]\n",
      "[[-1.058943    0.7005732   3.5553658 ]\n",
      " [-1.0977542   0.28137052  3.7307198 ]\n",
      " [-1.0468136  -0.18287832  3.8029544 ]\n",
      " [-1.2827559  -0.14506502  3.6233966 ]\n",
      " [-1.2914501   0.28222787  3.8316195 ]\n",
      " [-1.1815964   0.7037186   3.92526   ]\n",
      " [-0.96149117 -0.17398238  4.0351067 ]\n",
      " [-0.9870205  -0.3686945   3.8755767 ]\n",
      " [-1.1683757  -0.58851504  3.854682  ]\n",
      " [-1.3840907  -0.5406195   3.699018  ]\n",
      " [-1.382293   -0.2766148   3.573264  ]\n",
      " [-1.3576645  -0.01837389  3.5150688 ]\n",
      " [-1.2999516  -0.61188936  3.7955098 ]\n",
      " [-1.3872739  -0.7470877   3.8623822 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55169505"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fitting_error(joints[0],joints_metro[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "from modules.utils.image_utils import to_tensor, transform, transform_visualize, crop_box\n",
    "\n",
    "from modules.datasets.dataset_seq_3DPW import SequenceWise3DPW\n",
    "from modules.datasets.dataset_seq_H36M import SequenceWiseH36M\n",
    "from modules.datasets.FullDataset import get_full_seq_train_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h36m = SequenceWiseH36M(\n",
    "            data_path='../H36M',\n",
    "            subject_list=[9,11],\n",
    "            smpl=smpl.layer['neutral'],\n",
    "            load_from_zarr=None,\n",
    "            load_seq_datalist='/Users/clara/Desktop/MeineProjekte/H36M/data_pickle/seq_datalist_h36m_thr25_9to11subj.pickle',\n",
    "            load_datalist=None,\n",
    "            len_chunks=8,\n",
    "            img_size=224,\n",
    "            mask= False,\n",
    "            fitting_thr=25,\n",
    "            store_images=False,\n",
    "            backgrounds=None,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_h36m[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3dpw = SequenceWise3DPW(data_path='../3DPW',\n",
    "        split='train',\n",
    "        num_required_keypoints=8,\n",
    "        smpl=smpl.layer['neutral'],\n",
    "        len_chunks=8,\n",
    "        store_sequences=True,\n",
    "        store_images=False,\n",
    "        load_from_zarr='/Users/clara/Desktop/MeineProjekte/3DPW/img_zarr/imgs_3dpw_train.zarr',\n",
    "        img_size=224,\n",
    "        load_chunks_seq='/Users/clara/Desktop/MeineProjekte/3DPW/data_pickle/img_seqs_list_paths_seq/img_seqs_list_paths_seq_train_min8_kps.pickle',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_3dpw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize smpl model\n",
      "get 3dpw train data\n",
      "get 3dpw validation data\n",
      "get h36m train data\n",
      "get h36m validation data\n",
      "length train data: 3dpw: 2828, h36m: 9148, total: 11976\n",
      "length validation data: 3dpw: 1294, h36m: 9148, total: 10442\n"
     ]
    }
   ],
   "source": [
    "full_data = get_full_seq_train_val_data(\n",
    "        dataset='full',\n",
    "        data_path_3dpw='../3DPW',\n",
    "        len_chunks=8,\n",
    "        num_required_keypoints = 8,\n",
    "        store_sequences=True,\n",
    "        store_images_3dpw=True,\n",
    "        load_from_zarr_3dpw_trn=None,\n",
    "        load_from_zarr_3dpw_val=None,\n",
    "        img_size=224,\n",
    "        load_chunks_seq_trn='/Users/clara/Desktop/MeineProjekte/3DPW/data_pickle/img_seqs_list_paths_seq/img_seqs_list_paths_seq_train_min8_kps.pickle',\n",
    "        load_chunks_seq_val='/Users/clara/Desktop/MeineProjekte/3DPW/data_pickle/img_seqs_list_paths_seq/img_seqs_list_paths_seq_validation_min8_kps.pickle',\n",
    "        data_path_h36m='../H36M',\n",
    "        store_images_h36m=False,\n",
    "        load_from_zarr_h36m_trn=None,\n",
    "        load_from_zarr_h36m_val=None,\n",
    "        load_seq_datalist_trn='/Users/clara/Desktop/MeineProjekte/H36M/data_pickle/seq_datalist_h36m_thr25_9to11subj.pickle',\n",
    "        load_seq_datalist_val='/Users/clara/Desktop/MeineProjekte/H36M/data_pickle/seq_datalist_h36m_thr25_9to11subj.pickle',\n",
    "        backgrounds=None,\n",
    "        mask=True,\n",
    "        val_on_h36m=True,\n",
    "        subject_list_trn=[9,11],\n",
    "        subject_list_val=[9,11],\n",
    "        fitting_thr=25,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = full_data[0]\n",
    "val_data= full_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['img_paths', 'imgs', 'betas', 'poses', 'trans', 'vertices', 'cam_pose', 'cam_intr'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=data.set_chunks(), \n",
    "                                        batch_size=batch_size_val, \n",
    "                                        shuffle=False,)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c500d23ff985f6e0d55aaada0dd5a9d76ecd6f50f4f40e50dce0e2bcc3272a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('ba-envjup': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
